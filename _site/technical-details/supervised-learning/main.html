<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Supervised Learning – DSAN-5000: Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/gu-logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">DSAN-5000: Project</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../report/report.html"> 
<span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-technical-details" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Technical details</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-technical-details">    
        <li>
    <a class="dropdown-item" href="../../technical-details/data-collection/main.html">
 <span class="dropdown-text">Data-collection</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/data-cleaning/main.html">
 <span class="dropdown-text">Data-cleaning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/eda/main.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/unsupervised-learning/main.html">
 <span class="dropdown-text">Unsupervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/supervised-learning/main.html">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/llm-usage-log.html">
 <span class="dropdown-text">LLM usage Log</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-and-motivation" id="toc-introduction-and-motivation" class="nav-link active" data-scroll-target="#introduction-and-motivation">Introduction and Motivation</a></li>
  <li><a href="#model-selection-and-code" id="toc-model-selection-and-code" class="nav-link" data-scroll-target="#model-selection-and-code">Model Selection and Code</a>
  <ul class="collapse">
  <li><a href="#model-rationale" id="toc-model-rationale" class="nav-link" data-scroll-target="#model-rationale">Model Rationale</a></li>
  <li><a href="#overview-of-algorithms" id="toc-overview-of-algorithms" class="nav-link" data-scroll-target="#overview-of-algorithms">Overview of Algorithms</a></li>
  <li><a href="#split-methods" id="toc-split-methods" class="nav-link" data-scroll-target="#split-methods">Split Methods</a></li>
  <li><a href="#dataset-proportions" id="toc-dataset-proportions" class="nav-link" data-scroll-target="#dataset-proportions">Dataset Proportions</a></li>
  <li><a href="#preprocessing-techniques" id="toc-preprocessing-techniques" class="nav-link" data-scroll-target="#preprocessing-techniques">Preprocessing Techniques</a></li>
  </ul></li>
  <li><a href="#multi-class-classification" id="toc-multi-class-classification" class="nav-link" data-scroll-target="#multi-class-classification">Multi Class Classification</a>
  <ul class="collapse">
  <li><a href="#model-evaluation-metrics" id="toc-model-evaluation-metrics" class="nav-link" data-scroll-target="#model-evaluation-metrics">Model Evaluation Metrics</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#implications" id="toc-implications" class="nav-link" data-scroll-target="#implications">Implications</a></li>
  </ul></li>
  <li><a href="#binary-classification" id="toc-binary-classification" class="nav-link" data-scroll-target="#binary-classification">Binary Classification</a>
  <ul class="collapse">
  <li><a href="#model-evaluation-metrics-1" id="toc-model-evaluation-metrics-1" class="nav-link" data-scroll-target="#model-evaluation-metrics-1">Model Evaluation Metrics</a></li>
  <li><a href="#results-1" id="toc-results-1" class="nav-link" data-scroll-target="#results-1">Results</a></li>
  <li><a href="#implications-1" id="toc-implications-1" class="nav-link" data-scroll-target="#implications-1">Implications</a></li>
  </ul></li>
  <li><a href="#linear-reggression" id="toc-linear-reggression" class="nav-link" data-scroll-target="#linear-reggression">Linear Reggression</a>
  <ul class="collapse">
  <li><a href="#model-evaluation-metrics-2" id="toc-model-evaluation-metrics-2" class="nav-link" data-scroll-target="#model-evaluation-metrics-2">Model Evaluation Metrics:</a></li>
  <li><a href="#results-2" id="toc-results-2" class="nav-link" data-scroll-target="#results-2">Results</a></li>
  <li><a href="#implications-2" id="toc-implications-2" class="nav-link" data-scroll-target="#implications-2">Implications</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#future-steps" id="toc-future-steps" class="nav-link" data-scroll-target="#future-steps">Future Steps</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Supervised Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-and-motivation" class="level2">
<h2 class="anchored" data-anchor-id="introduction-and-motivation">Introduction and Motivation</h2>
<p>While unsupervised learning helps uncover patterns in food waste data, supervised learning can provide actionable predictions that directly inform decision-making processes. Supervised learning techniques, such as classification and regression, are essential for predicting outcomes like the surplus dollar value of wasted food or classifying food donations based on nutritional composition. By training models on labeled data, we can predict which food items are most likely to be wasted, which can help inform better resource allocation and waste reduction strategies.</p>
<p>In this project, supervised learning will be used to predict the economic impact of food waste by estimating the dollar surplus associated with surplus food. This involves building regression models that take into account factors such as the nutritional content, environmental footprint, and food category to forecast economic losses. Additionally, classification models will be employed to identify which food donations are most suitable for redistribution based on their nutritional value and waste characteristics. These insights will guide the development of policies and practices to reduce food waste and its associated environmental and economic costs. By combining supervised learning with unsupervised insights, this project aims to create a comprehensive framework for mitigating food waste through data-driven strategies.</p>
</section>
<section id="model-selection-and-code" class="level2">
<h2 class="anchored" data-anchor-id="model-selection-and-code">Model Selection and Code</h2>
<p>Here, we have built and evaluated three distinct types of machine learning models to address different aspects of food waste prediction and resource optimization. These models—multi-class classification, binary classification, and regression—each tackle unique challenges and offer insights into different dimensions of food waste management.</p>
<ol type="1">
<li>Multi-Class Classification:</li>
</ol>
<p>The first model is a multi-class classification task, where the goal is to predict the primary disposal method for different food items based on their physical characteristics and nutritional content. In this case, the target variable is the disposal method, which can take on multiple possible values (e.g., composting, recycling, or landfill). By leveraging features such as water footprint, nutritional composition (e.g., calories, protein, fat), and food categories, we aim to predict the most likely disposal method for each food item. This model is particularly useful in scenarios where the disposal method needs to be optimized based on the type of food waste, offering insights into how different food characteristics influence disposal choices.</p>
<ol start="2" type="1">
<li>Binary Classification:</li>
</ol>
<p>The second model is a binary classification task, which is designed to predict whether a given food item is fit for human consumption or not. This model uses various nutritional and environmental features as inputs, including surplus quantities, water footprint, and food characteristics. The target variable is binary: a food item is either classified as fit for consumption (0) or not fit for consumption (1). This binary classification task is valuable for food waste management systems where the goal is to separate consumable food from inedible or waste-bound food. The model’s output can guide decisions about redistribution, donation, or disposal, thus helping reduce food wastage by ensuring that edible food is appropriately utilized.</p>
<ol start="3" type="1">
<li>Regression:</li>
</ol>
<p>The third model is a regression task, which predicts the surplus value of food in US dollars based on various physical and nutritional features. Unlike classification, regression involves predicting a continuous variable—in this case, the monetary value of surplus food. The model utilizes features like food categories, nutritional content, and water footprint to estimate the financial surplus. This type of model is instrumental in helping organizations quantify the economic impact of food waste and identify opportunities for recovering value from surplus food. By accurately predicting the surplus value, the model can inform decisions around reselling, donating, or optimizing the food supply chain for maximum economic benefit.</p>
<section id="model-rationale" class="level3">
<h3 class="anchored" data-anchor-id="model-rationale">Model Rationale</h3>
<p>The choice of models—K-Nearest Neighbors (KNN), Random Forest, and Support Vector Machines (SVM)—was guided by their complementary strengths.</p>
<p>• KNN: Selected for its simplicity and effectiveness in handling multiclass problems with non-linear decision boundaries.</p>
<p>• Random Forest: Chosen for its robust performance across diverse datasets, ability to handle high-dimensional data, and built-in feature importance evaluation.</p>
<p>• SVM: Included for its strength in finding optimal hyperplanes in high-dimensional spaces and its kernel flexibility for complex decision boundaries.</p>
</section>
<section id="overview-of-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-algorithms">Overview of Algorithms</h3>
<p>• KNN: Classifies samples by majority voting among k nearest neighbors in the feature space, using distance metrics like Manhattan or Euclidean.</p>
<p>• Random Forest: Constructs multiple decision trees during training, averaging their outputs for classification to reduce overfitting and variance.</p>
<p>• SVM: Uses a hyperplane to separate classes with maximum margin and can apply non-linear kernels such as RBF for complex classification tasks.</p>
</section>
<section id="split-methods" class="level3">
<h3 class="anchored" data-anchor-id="split-methods">Split Methods</h3>
<p>The dataset was divided into training and testing subsets using a train-test split, ensuring that the model’s performance generalizes to unseen data. Additionally, cross-validation (GridSearchCV) was used during hyperparameter tuning to assess the model’s stability and avoid overfitting.</p>
</section>
<section id="dataset-proportions" class="level3">
<h3 class="anchored" data-anchor-id="dataset-proportions">Dataset Proportions</h3>
<p>The dataset was split into 80% training data and 20% testing data to ensure adequate data for both model training and evaluation.</p>
</section>
<section id="preprocessing-techniques" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing-techniques">Preprocessing Techniques</h3>
<p>Normalization</p>
<p>A StandardScaler was applied to normalize the feature variables, ensuring that all features have zero mean and unit variance. This step was particularly critical for algorithms like SVM and KNN, which are sensitive to the scale of input data.</p>
<p>Balancing the Dataset</p>
<p>Class imbalances were addressed using SMOTE (Synthetic Minority Oversampling Technique) combined with ENN (Edited Nearest Neighbors) via SMOTEENN. This method oversamples the minority classes and removes noisy samples near class boundaries, ensuring balanced class representation in the training data.</p>
<div id="cell-2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, StandardScaler</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.combine <span class="im">import</span> SMOTEENN</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error, r2_score</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SupervisedLearning:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_test <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_train <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_test <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> prepare_data(<span class="va">self</span>, input_features, target_feature, test_size<span class="op">=</span><span class="fl">0.2</span>, val_size<span class="op">=</span><span class="fl">0.2</span>, balance_data<span class="op">=</span><span class="va">True</span>, cat_target <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Drop rows with missing target or feature values</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> <span class="va">self</span>.data.dropna(subset<span class="op">=</span>input_features <span class="op">+</span> [target_feature])</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract features and target</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> <span class="va">self</span>.data[input_features]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> <span class="va">self</span>.data[target_feature]</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cat_target:</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Further split training+validation into training and validation sets</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Split into training+validation and test sets</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            X_train_val, X_test, y_train_val, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>                X, y, test_size<span class="op">=</span>test_size, stratify<span class="op">=</span>y, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>            X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>                X_train_val, y_train_val, test_size<span class="op">=</span>val_size <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> test_size), stratify<span class="op">=</span>y_train_val, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Split into training+validation and test sets</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            X_train_val, X_test, y_train_val, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>                X, y, test_size<span class="op">=</span>test_size, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>            X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>                X_train_val, y_train_val, test_size<span class="op">=</span>val_size <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> test_size), random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Balance the data using SMOTEENN if specified</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> balance_data:</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>            class_counts <span class="op">=</span> y_train.value_counts()</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>            min_class_samples <span class="op">=</span> class_counts.<span class="bu">min</span>()</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>            k_neighbors <span class="op">=</span> <span class="bu">min</span>(<span class="dv">5</span>, min_class_samples <span class="op">-</span> <span class="dv">1</span>)  <span class="co"># Ensure k_neighbors &lt; min_class_samples</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> k_neighbors <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"Skipping SMOTEENN as one or more classes have fewer than 2 samples."</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>                smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>, k_neighbors<span class="op">=</span>k_neighbors)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>                smoteenn <span class="op">=</span> SMOTEENN(random_state<span class="op">=</span><span class="dv">42</span>, smote<span class="op">=</span>smote)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>                X_train, y_train <span class="op">=</span> smoteenn.fit_resample(X_train, y_train)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the splits</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train, <span class="va">self</span>.X_val, <span class="va">self</span>.X_test <span class="op">=</span> X_train, X_val, X_test</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_train, <span class="va">self</span>.y_val, <span class="va">self</span>.y_test <span class="op">=</span> y_train, y_val, y_test</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> multiclass_classification(<span class="va">self</span>, input_features, target_feature, model_type<span class="op">=</span><span class="st">"knn"</span>, use_scaling<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>model_params):</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Standardize the features if required</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_scaling:</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>            scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_train <span class="op">=</span> scaler.fit_transform(<span class="va">self</span>.X_train)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_test <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_test)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_val <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_val)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choose model and perform tuning (if applicable)</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_type <span class="op">==</span> <span class="st">"knn"</span>:</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_neighbors'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>                <span class="st">'weights'</span>: [<span class="st">'uniform'</span>, <span class="st">'distance'</span>],</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>                <span class="st">'metric'</span>: [<span class="st">'euclidean'</span>, <span class="st">'manhattan'</span>]</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(KNeighborsClassifier(), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> model_type <span class="op">==</span> <span class="st">"random_forest"</span>:</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_depth'</span>: [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>],</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>]</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(RandomForestClassifier(class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">42</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> model_type <span class="op">==</span> <span class="st">"svm"</span>:</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>                <span class="st">'C'</span>: [<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="dv">10</span>],</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>                <span class="st">'kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>],</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>                <span class="st">'gamma'</span>: [<span class="st">'scale'</span>, <span class="st">'auto'</span>]</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(SVC(class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">42</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported model_type. Use 'knn', 'random_forest', or 'svm'."</span>)</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the GridSearchCV model</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grid_search_model.fit(<span class="va">self</span>.X_train, <span class="va">self</span>.y_train)</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve best estimator and parameters</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> <span class="va">self</span>.grid_search_model.best_estimator_</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, <span class="va">self</span>.grid_search_model.best_params_)</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Best Cross-Validation Score:"</span>, <span class="va">self</span>.grid_search_model.best_score_)</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predictions</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> <span class="va">self</span>.model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(<span class="va">self</span>.y_test, y_pred))</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plotting Confusion Matrix</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>        disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span><span class="va">self</span>.model.classes_)</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>        disp.plot(cmap<span class="op">=</span><span class="st">'viridis'</span>, values_format<span class="op">=</span><span class="st">'d'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">"Confusion Matrix"</span>)</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Feature importance plot (for models that support it)</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_type <span class="op">==</span> <span class="st">"random_forest"</span>:</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>            feature_importances <span class="op">=</span> <span class="va">self</span>.model.feature_importances_</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>            sns.barplot(x<span class="op">=</span>feature_importances, y<span class="op">=</span>input_features)</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="st">"Feature Importances"</span>)</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>            plt.show()</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Returning model and metrics for further analysis</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="va">self</span>.model,</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classification_report"</span>: classification_report(<span class="va">self</span>.y_test, y_pred, output_dict<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>            <span class="st">"confusion_matrix"</span>: cm</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> one_hot_encode(<span class="va">self</span>, column):</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="co">        One-hot encode a specified categorical column in the dataset.</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="co">            column (str): The name of the column to be one-hot encoded.</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> column <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.data.columns:</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Column '</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">' not found in the dataset."</span>)</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform one-hot encoding</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>        encoded_columns <span class="op">=</span> pd.get_dummies(<span class="va">self</span>.data[column], prefix<span class="op">=</span>column)</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Drop the original column and concatenate the new one-hot encoded columns</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> pd.concat([<span class="va">self</span>.data.drop(columns<span class="op">=</span>[column]), encoded_columns], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"One-hot encoded column '</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">' and updated the dataset."</span>)</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> regression(<span class="va">self</span>, input_features, target_feature, model_type<span class="op">=</span><span class="st">"random_forest"</span>, use_scaling<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>model_params):</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Standardize the features if required</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_scaling:</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>            scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_train <span class="op">=</span> scaler.fit_transform(<span class="va">self</span>.X_train)</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_test <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_test)</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_val <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_val)</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choose model and define parameter grid</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_type <span class="op">==</span> <span class="st">"random_forest"</span>:</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>],</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>],</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>]</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> model_type <span class="op">==</span> <span class="st">"linear_regression"</span>:</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> LinearRegression()</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported model_type. Use 'random_forest' or 'linear_regression'."</span>)</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the model</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grid_search_model.fit(<span class="va">self</span>.X_train, <span class="va">self</span>.y_train)</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If GridSearchCV was used, get the best estimator</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_type <span class="op">==</span> <span class="st">"random_forest"</span>:</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model <span class="op">=</span> <span class="va">self</span>.grid_search_model.best_estimator_</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, <span class="va">self</span>.grid_search_model.best_params_)</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Best Cross-Validation Score:"</span>, <span class="va">self</span>.grid_search_model.best_score_)</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model <span class="op">=</span> <span class="va">self</span>.grid_search_model</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predictions</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> <span class="va">self</span>.model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation Metrics</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>        mse <span class="op">=</span> mean_squared_error(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>        mae <span class="op">=</span> mean_absolute_error(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>        r2 <span class="op">=</span> r2_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Mean Squared Error (MSE):"</span>, mse)</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Mean Absolute Error (MAE):"</span>, mae)</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"R-squared (R2):"</span>, r2)</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Returning model and metrics for further analysis</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="va">self</span>.model,</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mse"</span>: mse,</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mae"</span>: mae,</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>            <span class="st">"r2"</span>: r2</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> binary_classification(<span class="va">self</span>, input_features, target_feature, model_type<span class="op">=</span><span class="st">"random_forest"</span>, use_scaling<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>model_params):</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Standardize the features if required</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_scaling:</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>            scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_train <span class="op">=</span> scaler.fit_transform(<span class="va">self</span>.X_train)</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_test <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_test)</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X_val <span class="op">=</span> scaler.transform(<span class="va">self</span>.X_val)</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choose model and perform tuning (if applicable)</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_type <span class="op">==</span> <span class="st">"knn"</span>:</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_neighbors'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>                <span class="st">'weights'</span>: [<span class="st">'uniform'</span>, <span class="st">'distance'</span>],</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>                <span class="st">'metric'</span>: [<span class="st">'euclidean'</span>, <span class="st">'manhattan'</span>]</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(KNeighborsClassifier(), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> model_type <span class="op">==</span> <span class="st">"random_forest"</span>:</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>                <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>,<span class="dv">15</span>, <span class="dv">20</span>],</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>],</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>]</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(RandomForestClassifier(class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">42</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> model_type <span class="op">==</span> <span class="st">"svm"</span>:</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>            param_grid <span class="op">=</span> {</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>                <span class="st">'C'</span>: [<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>                <span class="st">'kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>],</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>                <span class="st">'gamma'</span>: [<span class="st">'scale'</span>, <span class="st">'auto'</span>]</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grid_search_model <span class="op">=</span> GridSearchCV(SVC(class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">42</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported model_type. Use 'knn', 'random_forest', or 'svm'."</span>)</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the GridSearchCV model</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grid_search_model.fit(<span class="va">self</span>.X_train, <span class="va">self</span>.y_train)</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve best estimator and parameters</span></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> <span class="va">self</span>.grid_search_model.best_estimator_</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, <span class="va">self</span>.grid_search_model.best_params_)</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Best Cross-Validation Score:"</span>, <span class="va">self</span>.grid_search_model.best_score_)</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predictions</span></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> <span class="va">self</span>.model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(<span class="va">self</span>.y_test, y_pred))</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plotting Confusion Matrix</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>        disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span><span class="va">self</span>.model.classes_)</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>        disp.plot(cmap<span class="op">=</span><span class="st">'viridis'</span>, values_format<span class="op">=</span><span class="st">'d'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">"Confusion Matrix"</span>)</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Returning model and metrics for further analysis</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="va">self</span>.model,</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classification_report"</span>: classification_report(<span class="va">self</span>.y_test, y_pred, output_dict<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>            <span class="st">"confusion_matrix"</span>: cm</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>        }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'../../data/processed-data/food_merged.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>category_columns <span class="op">=</span> [</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tons_donations'</span>, <span class="st">'tons_industrial_uses'</span>, <span class="st">'tons_animal_feed'</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tons_anaerobic_digestion'</span>, <span class="st">'tons_composting'</span>, <span class="st">'tons_not_harvested'</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tons_incineration'</span>, <span class="st">'tons_land_application'</span>, <span class="st">'tons_landfill'</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tons_sewer'</span>, <span class="st">'tons_dumping'</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'total'</span>] <span class="op">=</span> data[category_columns].<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the percentage of total for each column</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>percentage_df <span class="op">=</span> data[category_columns].div(data[<span class="st">'total'</span>], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the column with the maximum percentage for each row</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'disposal_method'</span>] <span class="op">=</span> percentage_df.idxmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'disposal_method'</span>] <span class="op">=</span> data[<span class="st">'disposal_method'</span>].<span class="bu">str</span>.replace(<span class="st">'tons_'</span>, <span class="st">''</span>, regex<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the total column if no longer needed</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>data.drop(columns<span class="op">=</span>[<span class="st">'total'</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'donation_bin'</span>] <span class="op">=</span> np.where(data[<span class="st">'tons_donations'</span>] <span class="op">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(7084, 42)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/sj/4yswlk7n08x8jfcfnyw2vkqw0000gn/T/ipykernel_89931/718609560.py:16: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError
  data['disposal_method'] = percentage_df.idxmax(axis=1)</code></pre>
</div>
</div>
</section>
</section>
<section id="multi-class-classification" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-classification">Multi Class Classification</h2>
<p>This implementation aims to predict the disposal method—the primary way a specific type of food waste is handled—using machine learning models in a multiclass classification framework. The target variable is disposal_method, which includes categories such as landfill, composting, animal_feed, not_harvested, and sewer.</p>
<p>The feature variables used for prediction are:</p>
<p>• Physical Waste Characteristics: tons_surplus, tons_supply, tons_waste, tons_inedible_parts</p>
<p>• Environmental Impact Factor: gallons_water_footprint</p>
<p>• Nutritional Composition: serving_size, calories, protein, fat, carbs, fiber, calcium, iron, sodium</p>
<p>By leveraging these features, the project seeks to identify patterns in waste management, enabling better decision-making for sustainability and resource optimization across the food supply chain.</p>
<div id="cell-5" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>feature_columns <span class="op">=</span> [</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tons_surplus'</span>, <span class="st">'tons_supply'</span>, <span class="st">'tons_waste'</span>, <span class="st">'tons_inedible_parts'</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gallons_water_footprint'</span>, <span class="st">'serving_size'</span>, <span class="st">'calories'</span>, <span class="st">'protein'</span>, <span class="st">'fat'</span>, <span class="st">'carbs'</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiber'</span>, <span class="st">'calcium'</span>, <span class="st">'iron'</span>, <span class="st">'sodium'</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>target_column <span class="op">=</span> <span class="st">'disposal_method'</span>  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>learner <span class="op">=</span> SupervisedLearning(data)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>learner.prepare_data(feature_columns, target_column)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- KNN Model Testing ---"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>knn_result <span class="op">=</span> learner.multiclass_classification(</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    input_features<span class="op">=</span>feature_columns,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    target_feature<span class="op">=</span>target_column,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    model_type<span class="op">=</span><span class="st">"knn"</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained KNN Model Parameters:"</span>, knn_result[<span class="st">"model"</span>].get_params())</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Random Forest Model Testing ---"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>random_forest_result <span class="op">=</span> learner.multiclass_classification(</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    input_features<span class="op">=</span>feature_columns,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    target_feature<span class="op">=</span>target_column,</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    model_type<span class="op">=</span><span class="st">"random_forest"</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Best Parameters and Model Output</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained Model Parameters:"</span>, random_forest_result[<span class="st">"model"</span>].get_params())</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM Testing</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- SVM Model Testing ---"</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>svm_result <span class="op">=</span> learner.multiclass_classification(</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    input_features<span class="op">=</span>feature_columns,</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    target_feature<span class="op">=</span>target_column,</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    model_type<span class="op">=</span><span class="st">"svm"</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained SVM Model Parameters:"</span>, svm_result[<span class="st">"model"</span>].get_params())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- KNN Model Testing ---
Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}
Best Cross-Validation Score: 0.9859447031830759
Classification Report:
                precision    recall  f1-score   support

  animal_feed       1.00      1.00      1.00         3
   composting       0.79      0.95      0.86       123
     landfill       0.99      0.92      0.95       961
not_harvested       0.80      0.97      0.88       137
        sewer       0.75      1.00      0.86        39

     accuracy                           0.93      1263
    macro avg       0.87      0.97      0.91      1263
 weighted avg       0.94      0.93      0.93      1263
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trained KNN Model Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}

--- Random Forest Model Testing ---
Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}
Best Cross-Validation Score: 0.9934739579764355
Classification Report:
                precision    recall  f1-score   support

  animal_feed       1.00      1.00      1.00         3
   composting       0.83      0.94      0.88       123
     landfill       0.99      0.92      0.95       961
not_harvested       0.72      0.96      0.82       137
        sewer       0.87      1.00      0.93        39

     accuracy                           0.93      1263
    macro avg       0.88      0.97      0.92      1263
 weighted avg       0.94      0.93      0.93      1263
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-4-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-4-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trained Model Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}

--- SVM Model Testing ---
Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}
Best Cross-Validation Score: 0.9444031722852726
Classification Report:
                precision    recall  f1-score   support

  animal_feed       0.50      1.00      0.67         3
   composting       0.41      0.97      0.58       123
     landfill       0.99      0.76      0.86       961
not_harvested       0.55      0.72      0.62       137
        sewer       0.72      1.00      0.84        39

     accuracy                           0.78      1263
    macro avg       0.64      0.89      0.71      1263
 weighted avg       0.88      0.78      0.81      1263
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-4-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trained SVM Model Parameters: {'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': 'balanced', 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}</code></pre>
</div>
</div>
<section id="model-evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-metrics">Model Evaluation Metrics</h3>
<section id="multiclass-classification-metrics" class="level4">
<h4 class="anchored" data-anchor-id="multiclass-classification-metrics">Multiclass Classification Metrics</h4>
<p>• Accuracy: Measures the percentage of correctly classified samples across all classes.</p>
<p>• Precision, Recall, F1-Score: Evaluates the model’s performance for each class, balancing false positives and false negatives.</p>
<p>• Confusion Matrix: Used to visualize the distribution of predictions across classes.</p>
<p>• Cross-Validation Score: Captures model consistency by evaluating performance across multiple data splits.</p>
</section>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<ol type="1">
<li><p>KNN:</p>
<p>• Best Cross-Validation Score: 0.986</p>
<p>• Classification Report: Demonstrated strong performance, particularly for large classes like landfill, while showing some variability for minority classes such as animal_feed.</p></li>
<li><p>Random Forest:</p>
<p>• Best Cross-Validation Score: 0.993</p>
<p>• Classification Report: Delivered excellent performance with well-balanced precision and recall across all classes, reflecting its robust nature in handling imbalanced datasets.</p></li>
<li><p>SVM:</p>
<p>• Best Cross-Validation Score: 0.944</p>
<p>• Classification Report: Achieved reasonable performance but struggled with smaller classes like animal_feed, likely due to limited data and the complexity of separating the classes.</p></li>
</ol>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<p>The results of this project provide valuable insights into food waste management practices. Accurate classification of disposal methods based on physical, environmental, and nutritional factors can:</p>
<p>• Enable targeted policy interventions for waste reduction.</p>
<p>• Inform stakeholders about the environmental impact of different disposal methods.</p>
<p>• Support resource allocation for improving sustainable waste management practices.</p>
<p>Future efforts could include expanding the dataset, incorporating additional features (e.g., geographic data), and exploring advanced ensemble techniques for even greater predictive accuracy.</p>
</section>
</section>
<section id="binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="binary-classification">Binary Classification</h2>
<p>Here, we aim to predict whether food will be donated or not based on its nutritional and physical attributes. The task is framed as a binary classification problem, where the target variable is donation_bin, which indicates if a food item is suitable for donation (1) or not (0).</p>
<p>The input features used for prediction include various food-related characteristics, such as:</p>
<p>• Environmental Impact Factor: gallons_water_footprint</p>
<p>• Nutritional Composition: serving_size, calories, protein, fat, carbs, fiber, calcium, iron, sodium</p>
<p>These features are intended to capture the physical and nutritional profile of food that may influence whether it’s fit for donation. The target variable is donation_bin, which represents whether the food item is suitable for donation</p>
<div id="cell-8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>input_features <span class="op">=</span> [</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gallons_water_footprint'</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'serving_size'</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'protein'</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fat'</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'carbs'</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'calories'</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiber'</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'calcium'</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'iron'</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sodium'</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Target feature (donation_bin)</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>target_feature <span class="op">=</span> <span class="st">'donation_bin'</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>sl <span class="op">=</span> SupervisedLearning(data)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for training (this will split the data and apply SMOTE if required)</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>sl.prepare_data(input_features, target_feature)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- KNN Model Testing ---"</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform binary classification with random forest (you can choose other models as well)</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>results_knn <span class="op">=</span> sl.binary_classification(input_features, target_feature, model_type<span class="op">=</span><span class="st">"knn"</span>, use_scaling<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Output the results</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_knn)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Random Forest Model Testing ---"</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>results_random_forest <span class="op">=</span> sl.binary_classification(input_features, target_feature, model_type<span class="op">=</span><span class="st">"random_forest"</span>, use_scaling<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Output the results</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_random_forest)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- SVM Model Testing ---"</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>results_svm <span class="op">=</span> sl.binary_classification(input_features, target_feature, model_type<span class="op">=</span><span class="st">"svm"</span>, use_scaling<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Output the results</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_svm)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- KNN Model Testing ---
Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}
Best Cross-Validation Score: 0.9394957867108717
Classification Report:
               precision    recall  f1-score   support

           0       0.88      0.85      0.87       609
           1       0.87      0.90      0.88       688

    accuracy                           0.88      1297
   macro avg       0.88      0.87      0.88      1297
weighted avg       0.88      0.88      0.88      1297
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'model': KNeighborsClassifier(metric='euclidean', n_neighbors=3, weights='distance'), 'classification_report': {'0': {'precision': 0.8822525597269625, 'recall': 0.8489326765188834, 'f1-score': 0.8652719665271966, 'support': 609.0}, '1': {'precision': 0.870604781997187, 'recall': 0.8997093023255814, 'f1-score': 0.8849177984274482, 'support': 688.0}, 'accuracy': 0.8758673862760216, 'macro avg': {'precision': 0.8764286708620748, 'recall': 0.8743209894222324, 'f1-score': 0.8750948824773224, 'support': 1297.0}, 'weighted avg': {'precision': 0.876073939003689, 'recall': 0.8758673862760216, 'f1-score': 0.8756931942429816, 'support': 1297.0}}, 'confusion_matrix': array([[517,  92],
       [ 69, 619]])}

--- Random Forest Model Testing ---
Best Parameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}
Best Cross-Validation Score: 0.965279734769996
Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.88      0.87       609
           1       0.89      0.87      0.88       688

    accuracy                           0.87      1297
   macro avg       0.87      0.87      0.87      1297
weighted avg       0.87      0.87      0.87      1297
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-5-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'model': RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=300,
                       random_state=42), 'classification_report': {'0': {'precision': 0.8585209003215434, 'recall': 0.8768472906403941, 'f1-score': 0.867587327376117, 'support': 609.0}, '1': {'precision': 0.8888888888888888, 'recall': 0.872093023255814, 'f1-score': 0.880410858400587, 'support': 688.0}, 'accuracy': 0.874325366229761, 'macro avg': {'precision': 0.8737048946052162, 'recall': 0.874470156948104, 'f1-score': 0.873999092888352, 'support': 1297.0}, 'weighted avg': {'precision': 0.8746297485361414, 'recall': 0.874325366229761, 'f1-score': 0.8743896321909476, 'support': 1297.0}}, 'confusion_matrix': array([[534,  75],
       [ 88, 600]])}

--- SVM Model Testing ---
Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
Best Cross-Validation Score: 0.7290716949854953
Classification Report:
               precision    recall  f1-score   support

           0       0.76      0.43      0.55       609
           1       0.64      0.88      0.74       688

    accuracy                           0.67      1297
   macro avg       0.70      0.66      0.64      1297
weighted avg       0.69      0.67      0.65      1297
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-5-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'model': SVC(C=10, class_weight='balanced', gamma='auto', random_state=42), 'classification_report': {'0': {'precision': 0.7586206896551724, 'recall': 0.43349753694581283, 'f1-score': 0.5517241379310345, 'support': 609.0}, '1': {'precision': 0.6364594309799789, 'recall': 0.877906976744186, 'f1-score': 0.7379352474037875, 'support': 688.0}, 'accuracy': 0.669236700077101, 'macro avg': {'precision': 0.6975400603175756, 'recall': 0.6557022568449995, 'f1-score': 0.644829692667411, 'support': 1297.0}, 'weighted avg': {'precision': 0.6938196518999425, 'recall': 0.669236700077101, 'f1-score': 0.6505007326243684, 'support': 1297.0}}, 'confusion_matrix': array([[264, 345],
       [ 84, 604]])}</code></pre>
</div>
</div>
<section id="model-evaluation-metrics-1" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-metrics-1">Model Evaluation Metrics</h3>
<section id="binary-classification-metrics" class="level4">
<h4 class="anchored" data-anchor-id="binary-classification-metrics">Binary Classification Metrics</h4>
<p>• Accuracy: Measures the percentage of correctly classified samples across all classes.</p>
<p>• Precision, Recall, F1-Score: Evaluates the model’s performance for each class, balancing false positives and false negatives.</p>
<p>• Confusion Matrix: Used to visualize the distribution of predictions across classes.</p>
<p>• Cross-Validation Score: Captures model consistency by evaluating performance across multiple data splits.</p>
</section>
</section>
<section id="results-1" class="level3">
<h3 class="anchored" data-anchor-id="results-1">Results</h3>
<ol type="1">
<li><p>KNN:</p>
<p>• Best Cross-Validation Score: 0.939</p></li>
<li><p>Random Forest:</p>
<p>• Best Cross-Validation Score: 0.965</p></li>
<li><p>SVM:</p>
<p>• Best Cross-Validation Score: 0.729</p></li>
</ol>
</section>
<section id="implications-1" class="level3">
<h3 class="anchored" data-anchor-id="implications-1">Implications</h3>
<p>• Model Performance: The Random Forest and KNN models performed well, with accuracy scores of approximately 87% and 88%, respectively. These models also showed a good balance of precision and recall, especially for class 1 (donation), where recall was higher than precision, suggesting that the models are better at identifying suitable donation items.</p>
<p>• Model Comparison: The SVM model, despite having a high recall for class 1, struggled with precision and overall accuracy. This suggests that SVM might be less suited for this particular classification task, especially if false positives are a significant concern.</p>
<p>• Practical Application: A high-performing model can help in identifying food items that are eligible for donation, which can be leveraged in food recovery programs. The models can help reduce food waste by accurately predicting which food is fit for donation based on its nutritional and physical properties.</p>
</section>
</section>
<section id="linear-reggression" class="level2">
<h2 class="anchored" data-anchor-id="linear-reggression">Linear Reggression</h2>
<p>This analysis involves testing two regression models (Random Forest and Linear Regression) to predict the us_dollars_surplus of food items. The dataset includes features such as nutritional content and water footprint, along with one-hot encoded values for the food_category column. The goal is to predict the surplus value (in dollars) based on these characteristics, and the models’ performance is assessed using common regression metrics.</p>
<p>The input features used for prediction include various food-related characteristics, such as:</p>
<p>• Environmental Impact Factor: gallons_water_footprint</p>
<p>• Nutritional Composition: serving_size, calories, protein, fat, carbs, fiber, calcium, iron, sodium</p>
<p>• One Hot Encoded Food Category: food_category</p>
<section id="model-evaluation-metrics-2" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-metrics-2">Model Evaluation Metrics:</h3>
<p>The evaluation metrics provide a way to assess how well each model performs on the regression task. The primary metrics used here are:</p>
<p>• Mean Squared Error (MSE): This metric quantifies the average squared difference between the actual and predicted values. A lower MSE indicates a better fit of the model to the data.</p>
<p>• Mean Absolute Error (MAE): This metric gives the average of the absolute differences between predicted and actual values. Like MSE, a lower MAE is preferred, but it is less sensitive to outliers compared to MSE.</p>
<p>• R-squared (R²): This metric indicates the proportion of the variance in the target variable that is predictable from the independent variables. An R² value closer to 1 means the model explains most of the variance in the data, while a value closer to 0 suggests a poor fit.</p>
<div id="cell-11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the class</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>sl <span class="op">=</span> SupervisedLearning(data)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the 'food_category' column</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>sl.one_hot_encode(<span class="st">'food_category'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define input and target features</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>input_features <span class="op">=</span> [</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gallons_water_footprint'</span>, <span class="st">'protein'</span>, <span class="st">'fat'</span>, <span class="st">'carbs'</span>, <span class="st">'calories'</span>, <span class="st">'fiber'</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'calcium'</span>, <span class="st">'iron'</span>, <span class="st">'sodium'</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>] <span class="op">+</span> [col <span class="cf">for</span> col <span class="kw">in</span> sl.data.columns <span class="cf">if</span> col.startswith(<span class="st">'food_category_'</span>)]  </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>target_feature <span class="op">=</span> <span class="st">'us_dollars_surplus'</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>sl.prepare_data(input_features, target_feature, cat_target <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform regression</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Random Forest Model Testing ---"</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>results_rf <span class="op">=</span> sl.regression(input_features, target_feature, model_type<span class="op">=</span><span class="st">"random_forest"</span>, use_scaling<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_rf)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform regression</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Linear Reggression Model Testing ---"</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>results_lr <span class="op">=</span> sl.regression(input_features, target_feature, model_type<span class="op">=</span><span class="st">"linear_regression"</span>, use_scaling<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>One-hot encoded column 'food_category' and updated the dataset.
Skipping SMOTEENN as one or more classes have fewer than 2 samples.

--- Random Forest Model Testing ---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/shanaywadhwani/Desktop/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast
  _data = np.array(data, dtype=dtype, copy=copy,</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}
Best Cross-Validation Score: 0.9692753382410217
Mean Squared Error (MSE): 1.0930396794092634e+16
Mean Absolute Error (MAE): 54092284.88337758
R-squared (R2): 0.9679093204991429
{'model': RandomForestRegressor(max_depth=20, max_features='sqrt', random_state=42), 'mse': 1.0930396794092634e+16, 'mae': 54092284.88337758, 'r2': 0.9679093204991429}

--- Linear Reggression Model Testing ---
Mean Squared Error (MSE): 8.536678751781533e+16
Mean Absolute Error (MAE): 156127623.3713102
R-squared (R2): 0.7493706523323531
{'model': LinearRegression(), 'mse': 8.536678751781533e+16, 'mae': 156127623.3713102, 'r2': 0.7493706523323531}</code></pre>
</div>
</div>
</section>
<section id="results-2" class="level3">
<h3 class="anchored" data-anchor-id="results-2">Results</h3>
<p><strong>Random Forest Model</strong>:</p>
<p>The Random Forest model’s high R² value (96.79%) and relatively low error metrics (MSE and MAE) suggest that it is well-suited for predicting us_dollars_surplus in this context. The model’s ability to capture complex, non-linear relationships between the input features (such as nutritional content, water footprint, and food category) makes it a powerful tool for this regression task. The strong performance of the Random Forest model implies that the factors influencing food surplus are likely complex and interdependent, and a tree-based approach that considers interactions between variables is optimal.</p>
<p>Implications for Decision-Making:</p>
<p>• This model can be trusted to provide relatively accurate estimates of food surplus, which is crucial for resource management, sustainability efforts, and forecasting food waste reduction strategies.</p>
<p>• The high R² also suggests that predictive decisions (e.g., optimizing food donations based on surplus values) can be made with a high degree of confidence.</p>
<p><strong>Linear Regression Model</strong>:</p>
<p>The Linear Regression model, with an R² of 74.94%, performs substantially worse than Random Forest. This indicates that the relationships between the features and the target variable may not be well-represented by a simple linear model. Although Linear Regression is often favored for its interpretability and simplicity, its performance in this case implies that the problem might require more sophisticated models to capture the intricate interactions between variables.</p>
<p>Implications for Decision-Making:</p>
<p>• While Linear Regression could still be used in scenarios requiring fast and interpretable predictions, it might lead to less reliable decisions in complex situations where non-linearities and interactions between features are critical.</p>
<p>• The model’s higher error metrics highlight the need for further refinement, such as feature engineering or incorporating more sophisticated modeling techniques, to improve accuracy in food surplus predictions.</p>
</section>
<section id="implications-2" class="level3">
<h3 class="anchored" data-anchor-id="implications-2">Implications</h3>
<p>• Predicting Food Surplus: Accurate predictions of food surplus can significantly impact food redistribution strategies, enabling organizations to allocate resources more effectively, reduce food waste, and improve sustainability practices.</p>
<p>• This could lead to more efficient use of food resources, helping both to minimize waste and address hunger by redirecting surplus food to charitable organizations.</p>
<p>• Improved Policy and Operational Decision-Making: Decision-makers can use the insights derived from the Random Forest model to better plan for food production and distribution, ensuring that surplus food is identified early and directed to appropriate channels. This can also aid in developing policies that prioritize food sustainability and efficient use of resources.</p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>• Improved Waste Management: By leveraging these predictive models, we can optimize food waste management strategies, predicting the disposal methods most likely to be employed based on food characteristics. This could help businesses or organizations implement more efficient waste reduction practices and optimize recycling or composting initiatives.</p>
<p>• Environmental Impact: Predicting the surplus value and disposal method for food items can have substantial environmental implications. The models can provide insights into where food waste could be better managed (e.g., through donation, composting, or recycling), which would help reduce environmental harm by diverting waste from landfills. Furthermore, aligning food waste strategies with sustainability goals can contribute to a reduction in water, energy, and other resource consumption related to food production.</p>
<p>• Economic Value: The regression model predicting the surplus value in US dollars offers valuable insights for food supply chain optimization. By accurately forecasting the financial surplus related to food waste, businesses can make more informed decisions, potentially recovering value from surplus food, such as donating it, reselling it, or repurposing it for other uses.</p>
<p>• Behavioral Insights: With accurate predictions of food disposal methods and their economic impact, businesses can start to identify patterns in consumer behavior and food supply. This data could be used to devise better strategies to reduce food waste at various stages of the food supply chain—growing, processing, packaging, and consumption.</p>
<p>By focusing on continuous improvement and optimization of these models, there is potential to create a system that not only predicts food waste and disposal methods accurately but also contributes to long-term sustainability, waste reduction, and economic efficiency.</p>
</section>
<section id="future-steps" class="level2">
<h2 class="anchored" data-anchor-id="future-steps">Future Steps</h2>
<p>• Model Optimization: The current models (KNN, Random Forest, and Linear Regression) have demonstrated solid performance, but future steps should focus on further optimizing these models. For instance, hyperparameter tuning using GridSearchCV can be continued to refine model parameters, especially for Random Forest and SVM. Additionally, exploring more complex algorithms like Gradient Boosting or Neural Networks may lead to better performance, especially if the dataset grows in size.</p>
<p>• Feature Engineering: While the feature set used in the current models covers a broad range of nutritional and environmental factors, additional features could enhance the model’s predictive power. Investigating domain-specific features, such as food waste factors, consumer behavior, or additional environmental impacts, could provide a more holistic view of food disposal decisions. This might also involve combining features through transformations (e.g., interaction terms or polynomial features) to capture more intricate relationships.</p>
<p>• Data Quality and Expansion: The current models rely on a rich set of features, but improving data quality is always a continuous process. Handling outliers more robustly, filling missing values more effectively, and ensuring that categorical data is properly encoded (like the one-hot encoding of food categories) will help refine the models. Furthermore, expanding the dataset to include more diverse food categories or a broader geographical representation would help improve model generalization.</p>
<p>• Evaluation and Validation: Future work should focus on comprehensive evaluation metrics, beyond just accuracy, by including precision, recall, F1-score, and ROC-AUC in more detail to better handle class imbalance. This is especially relevant when predicting food waste, as the consequences of misclassification can be significant. Incorporating a more robust validation strategy, such as time-series cross-validation or k-fold cross-validation, may also help assess model stability and performance across different subsets of the data. • Model Optimization: The current models (KNN, Random Forest, and Linear Regression) have demonstrated solid performance, but future steps should focus on further optimizing these models. For instance, hyperparameter tuning using GridSearchCV can be continued to refine model parameters, especially for Random Forest and SVM. Additionally, exploring more complex algorithms like Gradient Boosting or Neural Networks may lead to better performance, especially if the dataset grows in size.</p>
<p>• Feature Engineering: While the feature set used in the current models covers a broad range of nutritional and environmental factors, additional features could enhance the model’s predictive power. Investigating domain-specific features, such as food waste factors, consumer behavior, or additional environmental impacts, could provide a more holistic view of food disposal decisions. This might also involve combining features through transformations (e.g., interaction terms or polynomial features) to capture more intricate relationships.</p>
<p>• Data Quality and Expansion: The current models rely on a rich set of features, but improving data quality is always a continuous process. Handling outliers more robustly, filling missing values more effectively, and ensuring that categorical data is properly encoded (like the one-hot encoding of food categories) will help refine the models. Furthermore, expanding the dataset to include more diverse food categories or a broader geographical representation would help improve model generalization.</p>
<p>• Evaluation and Validation: Future work should focus on comprehensive evaluation metrics, beyond just accuracy, by including precision, recall, F1-score, and ROC-AUC in more detail to better handle class imbalance. This is especially relevant when predicting food waste, as the consequences of misclassification can be significant. Incorporating a more robust validation strategy, such as time-series cross-validation or k-fold cross-validation, may also help assess model stability and performance across different subsets of the data.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>