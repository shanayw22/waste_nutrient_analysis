{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cleaning process for this project involved several key steps aimed at preparing the raw food waste and food data for analysis. Initially, we removed unnecessary columns and filtered the data based on relevant criteria, such as valid serving size units. We also handled missing data by dropping rows with missing values in critical fields, ensuring the integrity of the dataset.\n",
    "\n",
    "Next, we standardized measurement units by converting various food quantities to grams, ensuring consistency across the dataset. This was particularly important for nutritional analysis, where accurate comparisons are required. Additionally, we transformed specific columns (e.g., vitamins, cholesterol) into consistent units, further improving data uniformity.\n",
    "\n",
    "We applied fuzzy matching techniques to merge food waste data with cleaned food data based on food name similarities. The fuzzy join method, using difflib’s SequenceMatcher, allowed us to handle slight variations in food names between datasets and find the best matches.\n",
    "\n",
    "Throughout the process, we focused on ensuring that the data was in a format suitable for analysis, with correctly formatted data types, consistent units, and minimal missing or inconsistent data. This rigorous cleaning approach enables more reliable exploratory data analysis (EDA) and model building, setting the foundation for insightful analysis of food waste and nutrition.\n",
    "\n",
    "## Managing Missing Data\n",
    "\n",
    "•\tIdentify Missing Values: Missing values are common in real-world datasets and can occur for various reasons. In this project, missing data was identified in columns such as serving_size, protein, fat, carbs, calories, and other nutritional values. Using pandas’ isnull() function, the locations of missing values were pinpointed across the dataset.\n",
    "\n",
    "•\tHandling Missing Data: Several strategies were employed to handle missing data. For numerical columns like protein, fat, and calories, missing values were replaced with the mean of the column to retain the data’s overall distribution. In some cases, rows with missing critical data, such as serving_size, were dropped entirely to ensure the integrity of further analysis.\n",
    "\n",
    "## Outlier Detection and Treatment\n",
    "\n",
    "•\tIdentify Outliers: Outliers were detected using statistical methods such as Z-scores and box plots. Variables like serving_size, protein, fat, and other nutritional values were checked for extreme values that might indicate outliers.\n",
    "\n",
    "•\tAddressing Outliers: Outliers were addressed depending on their nature. In some cases, extreme values were capped or transformed, while in others, they were removed if they were clearly erroneous. Retaining outliers for analysis was also considered when they provided valuable insights into the data distribution.\n",
    "\n",
    "•\tVisualize Outliers: Box plots were used to visualize the outliers before and after handling. These plots illustrated the distribution of values and how outliers were managed in various columns. By comparing the before and after visualizations, the effect of outlier treatment on the dataset could be clearly seen.\n",
    "\n",
    "## Normalization and Scaling:\n",
    "\n",
    "•\tData Distribution Analysis: The distribution of numerical variables was initially analyzed using histograms and summary statistics to identify any skewness or irregular distributions. For example, variables like protein, carbs, and fat exhibited skewed distributions.\n",
    "\n",
    "•\tNormalization Techniques: To address this, normalization techniques such as min-max scaling and Z-score normalization were applied to certain columns. These methods ensured that variables with different ranges could be compared directly and improved the performance of certain machine learning models.\n",
    "\n",
    "•\tBefore-and-After Visualizations: Before and after visualizations, such as histograms and box plots, were used to compare the data distributions. The effect of normalization could be seen in the flattening of skewed distributions, making them more suitable for modeling.\n",
    "\n",
    "\n",
    "## Subsetting the Data\n",
    "\n",
    "•\tData Filtering: The data was subsetted to focus on relevant columns and remove irrelevant ones. For example, columns related to allergens, microbes, and country of origin were removed, as they were not directly relevant to the analysis of food waste and nutritional content. Filtering also involved focusing on specific food categories and nutritional attributes, such as protein, fat, calories, and fiber.\n",
    "\n",
    "•\tRationale: The rationale for filtering was to reduce the complexity of the data and focus on the most relevant features for analysis. By working with a smaller, more targeted subset, it was easier to perform focused analysis and avoid noise from unnecessary variables. The subsetted data was better suited for modeling and understanding the relationships between food waste and nutritional content.\n",
    "\n",
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import fitz  \n",
    "import pdfplumber\n",
    "from rapidfuzz import process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "food_data = pd.read_csv(\"data/raw-data/foods_data.csv\")\n",
    "food_waste = pd.read_csv(\"data/raw-data/ReFED_US_Food_Surplus_Detail.csv\")\n",
    "\n",
    "food_waste.drop(\n",
    "    ['Unnamed: 0','sector', 'sub_sector', 'sub_sector_category',\n",
    "       'food_type','surplus_upstream_100_year_mtco2e_footprint',\n",
    "     'surplus_downstream_100_year_mtco2e_footprint',\n",
    "     'surplus_total_100_year_mtco2e_footprint',\n",
    "     'surplus_upstream_100_year_mtch4_footprint',\n",
    "     'surplus_downstream_100_year_mtch4_footprint',\n",
    "     'surplus_total_100_year_mtch4_footprint'], \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "food_data.drop(\n",
    "    ['microbes', 'allergens', 'additives', 'labels',\n",
    "       'nutrient_group', 'brand_name', 'food_labels', 'package_size',\n",
    "       'food_safety_info', 'expiration_date', 'country_of_origin','fdc_id' ],\n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "valid_units = ['g', 'grm', 'gm', 'mlt', 'ml', 'mg']\n",
    "\n",
    "\n",
    "df_filtered = food_data[food_data['serving_size_unit'].str.lower().isin(valid_units)]\n",
    "\n",
    "df_filtered.columns\n",
    "\n",
    "def convert_to_grams(row, column):\n",
    "    unit = row['serving_size_unit'].lower()\n",
    "    \n",
    "    # If unit is grams (g, grm, gm), return the value as is\n",
    "    if unit in ['g', 'grm', 'gm']:\n",
    "        return row[column]\n",
    "    # If unit is milliliters (ml, mlt), assume 1 ml = 1 g (for liquids)\n",
    "    elif unit in ['ml', 'mlt']:\n",
    "        return row[column]  # Convert 1 ml to 1 g\n",
    "    # If unit is milligrams (mg), convert to grams\n",
    "    elif unit == 'mg':\n",
    "        return row[column] * 0.001  # 1 mg = 0.001 g\n",
    "    # If unit is unknown or unsupported, return the value as is\n",
    "    else:\n",
    "        return row[column]\n",
    "\n",
    "# List of columns to convert\n",
    "columns_to_convert = [\n",
    "    'serving_size', 'protein', 'percent_daily_value', 'fat', 'carbs', 'calories', \n",
    "    'fiber'\n",
    "]\n",
    "\n",
    "# Apply conversion to each specified column\n",
    "for column in columns_to_convert:\n",
    "    df_filtered[column] = df_filtered.apply(lambda row: convert_to_grams(row, column), axis=1)\n",
    "\n",
    "def convert_to_grams(row):\n",
    "    # Convert Vitamin A (IU to grams)\n",
    "    vitamin_a_grams = row['vitamin_a_iu'] * 0.0000003 if pd.notnull(row['vitamin_a_iu']) else None\n",
    "    \n",
    "    # Convert Vitamin C (mg to grams)\n",
    "    vitamin_c_grams = row['vitamin_c_mg'] * 0.001 if pd.notnull(row['vitamin_c_mg']) else None\n",
    "    \n",
    "    # Convert Cholesterol (mg to grams)\n",
    "    cholesterol_grams = row['cholesterol_mg'] * 0.001 if pd.notnull(row['cholesterol_mg']) else None\n",
    "    \n",
    "    return pd.Series({'vitamin_a_grams': vitamin_a_grams, 'vitamin_c_grams': vitamin_c_grams, 'cholesterol_grams': cholesterol_grams})\n",
    "\n",
    "# Apply the conversion function to the DataFrame\n",
    "df_filtered[['vitamin_a_grams', 'vitamin_c_grams', 'cholesterol_grams']] = df_filtered.apply(convert_to_grams, axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "df_filtered = df_filtered.drop(columns=['vitamin_a_iu', 'vitamin_c_mg', 'cholesterol_mg'])\n",
    "\n",
    "df_filtered = df_filtered.drop(columns=['brand', 'food_category', 'market_country'])\n",
    "\n",
    "df_filtered.columns\n",
    "df_filtered.head()\n",
    "\n",
    "def mean_excluding_nulls(series):\n",
    "    return series.dropna().mean()\n",
    "\n",
    "\n",
    "df_grouped = df_filtered.groupby('food_name').agg({\n",
    "    'serving_size': mean_excluding_nulls,\n",
    "    'protein': mean_excluding_nulls,\n",
    "    'percent_daily_value': mean_excluding_nulls,\n",
    "    'fat': mean_excluding_nulls,\n",
    "    'carbs': mean_excluding_nulls,\n",
    "    'calories': mean_excluding_nulls,\n",
    "    'fiber': mean_excluding_nulls,\n",
    "    'calcium': mean_excluding_nulls,\n",
    "    'iron': mean_excluding_nulls,\n",
    "    'potassium': mean_excluding_nulls,\n",
    "    'sodium': mean_excluding_nulls,\n",
    "    'phosphorus': mean_excluding_nulls\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_overlap(str1, str2):\n",
    "    matcher = SequenceMatcher(None, str1.lower(), str2.lower())\n",
    "    return matcher.ratio()  \n",
    "def find_best_match(food_name, df, used_matches):\n",
    "    best_match = None\n",
    "    highest_overlap = 0\n",
    "    best_index = -1\n",
    "    \n",
    "    \n",
    "    for idx, name2 in df['food_name'].items():  \n",
    "        if idx not in used_matches:\n",
    "            overlap = calculate_overlap(food_name, name2)\n",
    "            if overlap > highest_overlap:\n",
    "                best_match = name2\n",
    "                highest_overlap = overlap\n",
    "                best_index = idx\n",
    "    \n",
    "    return best_match, highest_overlap, best_index\n",
    "matches = []\n",
    "used_matches = set()\n",
    "\n",
    "for name1 in food_waste['food_name']:\n",
    "    best_match, score, best_index = find_best_match(name1, df_grouped, used_matches)\n",
    "    if best_match and score >= 0.60:  \n",
    "        matches.append({\n",
    "            'food_name_food_waste': name1, \n",
    "            'best_match': best_match, \n",
    "            'score': score\n",
    "        })\n",
    "        used_matches.add(best_index) \n",
    "\n",
    "matches_df = pd.DataFrame(matches)\n",
    "\n",
    "food_waste_renamed = food_waste.rename(columns={'food_name': 'food_name_food_waste'})\n",
    "\n",
    "result = pd.merge(food_waste_renamed, matches_df, left_on='food_name_food_waste', right_on='food_name_food_waste', how='left')\n",
    "\n",
    "\n",
    "result = pd.merge(result, df_grouped, left_on='best_match', right_on='food_name', how='left', suffixes=('_food_waste', '_grouped_df'))\n",
    "\n",
    "print(result)\n",
    "columns_to_convert = ['calcium', 'iron', 'potassium', 'sodium', 'phosphorus']\n",
    "\n",
    "#convert to grams\n",
    "for col in columns_to_convert:\n",
    "    if col in result.columns:\n",
    "        result[col] = result[col] / 1000\n",
    "\n",
    "#drop rows where serving_size is NA\n",
    "result = result.dropna(subset=['serving_size'])\n",
    "result.columns\n",
    "result.describe()\n",
    "\n",
    "result.to_csv('data/processed-data/food_merged.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
